Keep these guidelines in mind as you think through your comments

#### Style and Clarity Issues
- Awkward phrasing or constructions (suggest ways of rephrasing the text)
- Dense paragraphs that need splitting
- Confusing sentence structure
- Missing transitions
- Places where additional context is needed (would a knowledgeable reader get confused?) 

#### Content Issues
- Logical gaps or jumps in reasoning
- Unsupported or over-confident claims
- Missing counterarguments or caveats

#### Structure Issues
- Poor organization or flow
- Repetitive content
- Misplaced sections

**Good Comment Characteristics:**
- Specific about the issue
- Explains why it's problematic
- Suggests concrete improvements when possible

**Example of a good comment:**
> "Content: This objection—that retroactive reward is too infrequent to matter—is strong but dismissed quickly. If retroactive training happens 'a few times at most' per episode, and the reward seeker faces tradeoffs with immediate reward, why would this ever become a dominant motivation? You need a clearer argument for why even weak/infrequent retroactive reward would be selected for."

**Example of a bad comment:**
> "This is confusing." (Too vague, not constructive, no explanation)

#### Other notes
- Hedging: good rationalist writing can include phrases like "I think..." "It's plausible that..." to indicate different levels of uncertainty. This is generally fine. 

Recall Joe Carlsmith on Fake thinking and real thinking:
<quote>
Sometimes, my thinking feels more “real” to me; and sometimes, it feels more “fake.” I want to do the real version, so I want to understand this spectrum better. This essay offers some reflections. 

I give a bunch of examples of this “fake vs. real” spectrum below -- in AI, philosophy, competitive debate, everyday life, and religion. My current sense is that it brings together a cluster of related dimensions, namely:

    Map vs. world: Is my mind directed at an abstraction, or it is trying to see past its model to the world beyond?
    Hollow vs. solid: Am I using concepts/premises/frames that I secretly suspect are bullshit, or do I expect them to point at basically real stuff, even if imperfectly?
    Rote vs. new: Is the thinking pre-computed, or is new processing occurring?
    Soldier vs. scout: Is the thinking trying to defend a pre-chosen position, or is it just trying to get to the truth?
    Dry vs. visceral: Does the content feel abstract and heady, or does it grip me at some more gut level?

These dimensions aren’t the same. But I think they’re correlated – and I offer some speculations about why. In particular, I speculate about their relationship to the “telos” of thinking – that is, to the thing that thinking is “supposed to” do. 

I also describe some tags I’m currently using when I remind myself to “really think.” In particular: 

    Going slow
    Following curiosity/aliveness
    Staying in touch with why I’m thinking about something
    Tethering my concepts to referents that feel “real” to me
    Reminding myself that “arguments are lenses on the world”
    Tuning into a relaxing sense of “helplessness” about the truth
    Just actually imagining different ways the world could be
    Imagining myself being wrong/right in both directions
    Imagining what ideal future people who could see the full truth would think of my efforts
    Stamping my foot and saying “no bullshit!”
    Looking at the thing my archetype of a “real scientist” or a “real philosopher” is looking at.

I close with some reflections on the role of “real thinking” in staying awake as we enter the age of AI.   
</quote>

Promote real thinking in writing. Notice when the author hides complexity behind vague words/abstractions, if they use unsubstantiated assumptions, if they reuse cached ideas that might not actually apply to the specific case they are writing about.